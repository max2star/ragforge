#
#  Copyright 2024 The InfiniFlow Authors. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

# from beartype import BeartypeConf
# from beartype.claw import beartype_all  # <-- you didn't sign up for this
# beartype_all(conf=BeartypeConf(violation_type=UserWarning))    # <-- emit warnings from all code

from api.utils.log_utils import initRootLogger
initRootLogger("ragforge_server")

import logging
import os
import signal
import sys
import time
import traceback
from concurrent.futures import ThreadPoolExecutor
import threading
import uuid
import functools
import gc

from werkzeug.serving import run_simple
from api import settings
from api.apps import app
from api.db.runtime_config import RuntimeConfig
from api.db.services.document_service import DocumentService
from api import utils

from api.db.db_models import init_database_tables as init_web_db, close_connection
from api.db.init_data import init_web_data
from api.versions import get_ragforge_version
from api.utils import show_configs
from rag.settings import print_rag_settings
from rag.utils.redis_conn import RedisDistributedLock

stop_event = threading.Event()

RAGFORGE_DEBUGPY_LISTEN = int(os.environ.get('RAGFORGE_DEBUGPY_LISTEN', "0"))

def database_retry(max_retries=3, retry_delay=1):
    """æ•°æ®åº“æ“ä½œé‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    error_str = str(e).lower()

                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®åº“ç›¸å…³é”™è¯¯
                    is_db_error = any(keyword in error_str for keyword in [
                        'closed cursor', 'connection', 'database', 'timeout',
                        'lost connection', 'server has gone away', 'broken pipe'
                    ])

                    if is_db_error and attempt < max_retries - 1:
                        logging.warning(f"Database connection issue in {func.__name__} on attempt {attempt + 1}: {e}")
                        try:
                            # å¼ºåˆ¶å…³é—­æ‰€æœ‰è¿æ¥
                            close_connection()
                            # å¼ºåˆ¶åƒåœ¾å›æ”¶
                            gc.collect()
                        except Exception as cleanup_error:
                            logging.warning(f"Connection cleanup failed: {cleanup_error}")

                        # æŒ‡æ•°é€€é¿
                        sleep_time = retry_delay * (2 ** attempt)
                        time.sleep(sleep_time)
                        continue
                    else:
                        logging.error(f"{func.__name__} exception: {e}")
                        logging.error(f"Full traceback: {traceback.format_exc()}")
                        break

            if last_exception:
                # è®°å½•æœ€ç»ˆå¤±è´¥
                logging.error(f"{func.__name__} failed after {max_retries} attempts")
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›Noneé¿å…ç¨‹åºå´©æºƒ
                return None
            return None
        return wrapper
    return decorator

# æ·»åŠ è¿æ¥çŠ¶æ€ç›‘æ§
def log_database_status():
    """è®°å½•æ•°æ®åº“è¿æ¥çŠ¶æ€"""
    try:
        from api.db.db_models import DB
        if hasattr(DB, 'is_closed'):
            status = 'Closed' if DB.is_closed() else 'Connected'
        else:
            status = 'Unknown'
        logging.debug(f"Database connection status: {status}")
    except Exception as e:
        logging.warning(f"Failed to check database status: {e}")

# ä½¿ç”¨è£…é¥°å™¨ä¿®é¥° update_progress å‡½æ•°
@database_retry(max_retries=3, retry_delay=2)
def update_progress():
    lock_value = str(uuid.uuid4())
    redis_lock = RedisDistributedLock("update_progress", lock_value=lock_value, timeout=60)
    logging.info(f"update_progress lock_value: {lock_value}")
    result = None
    while not stop_event.is_set():
        try:
            if redis_lock.acquire():
                """æ›´æ–°æ–‡æ¡£å¤„ç†è¿›åº¦"""
                log_database_status()
                DocumentService.update_progress()
                result = True
                redis_lock.release()
            stop_event.wait(6)
        except Exception as e:
            logging.exception(f"update_progress exception: {e}")
        finally:
            redis_lock.release()
    return result

def safe_update_progress():
    """å®‰å…¨çš„è¿›åº¦æ›´æ–°å‡½æ•°ï¼Œé˜²æ­¢å´©æºƒ"""
    while not stop_event.is_set():
        try:
            # ç­‰å¾…30ç§’åæ‰§è¡Œ
            if stop_event.wait(30):
                break

            result = update_progress()
            if result is None:
                logging.warning("update_progress returned None")

        except Exception as e:
            logging.error(f"safe_update_progress caught exception: {e}")
            logging.error(f"Full traceback: {traceback.format_exc()}")

        # æ— è®ºæˆåŠŸå¤±è´¥éƒ½ç»§ç»­å¾ªç¯

def signal_handler(sig, frame):
    logging.info("Received interrupt signal, shutting down...")
    stop_event.set()
    logging.error(f"æ”¶åˆ°ä¿¡å· {sig}")
    logging.error(f"å½“å‰å †æ ˆ:")
    traceback.print_stack(frame)
    time.sleep(1)
    sys.exit(0)

# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGSEGV, signal_handler)  # æ®µé”™è¯¯
signal.signal(signal.SIGABRT, signal_handler)  # å¼‚å¸¸ç»ˆæ­¢

# æ·»åŠ å†…å­˜ç›‘æ§
def monitor_memory():
    """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    try:
        import psutil
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        logging.info(f"Memory usage: RSS={memory_info.rss / 1024 / 1024:.2f}MB, VMS={memory_info.vms / 1024 / 1024:.2f}MB")

        # å¦‚æœå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå¼ºåˆ¶åƒåœ¾å›æ”¶
        if memory_info.rss > 1024 * 1024 * 1024:  # 1GB
            logging.warning("High memory usage detected, forcing garbage collection")
            gc.collect()

    except ImportError:
        logging.debug("psutil not available, skipping memory monitoring")
    except Exception as e:
        logging.warning(f"Memory monitoring failed: {e}")

def periodic_maintenance():
    """å®šæœŸç»´æŠ¤ä»»åŠ¡"""
    while not stop_event.is_set():
        try:
            # æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ç»´æŠ¤
            if stop_event.wait(300):  # 5åˆ†é’Ÿ
                break

            logging.debug("Running periodic maintenance")

            # å†…å­˜ç›‘æ§
            monitor_memory()

            # æ•°æ®åº“è¿æ¥æ¸…ç†
            try:
                close_connection()
            except Exception as e:
                logging.warning(f"Database cleanup failed: {e}")

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()

        except Exception as e:
            logging.error(f"Periodic maintenance failed: {e}")

if __name__ == '__main__':
    logging.info("ğŸš€ RAGForge Server Starting...")
    logging.info(f'RAGForge version: {get_ragforge_version()}')
    logging.info(f'project base: {utils.file_utils.get_project_base_directory()}')

    try:
        show_configs()
        settings.init_settings()
        print_rag_settings()
    except Exception as e:
        logging.error(f"Configuration initialization failed: {e}")
        sys.exit(1)

    if RAGFORGE_DEBUGPY_LISTEN > 0:
        logging.info(f"debugpy listen on {RAGFORGE_DEBUGPY_LISTEN}")
        import debugpy
        debugpy.listen(("0.0.0.0", RAGFORGE_DEBUGPY_LISTEN))

    # init db
    # åªéœ€è¦æ‰§è¡Œä¸€æ¬¡ï¼ŒæˆåŠŸåæ³¨é‡Š
    #TODO è¿™ä¸ªæœ‰é…ç½®æ–‡ä»¶æ›´æ–°ç­‰éœ€è¦å†™å…¥æ•°æ®åº“ï¼Œä¸èƒ½åªæ‰§è¡Œä¸€æ¬¡;éœ€è¦ä¿®æ”¹
    init_web_db()
    init_web_data()

    # init runtime config
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--version", default=False, help="RAGForge version", action="store_true"
    )
    parser.add_argument(
        "--debug", default=False, help="debug mode", action="store_true"
    )
    args = parser.parse_args()
    if args.version:
        print(get_ragforge_version())
        sys.exit(0)

    RuntimeConfig.DEBUG = args.debug
    if RuntimeConfig.DEBUG:
        logging.info("run on debug mode")

    try:
        RuntimeConfig.init_env()
        RuntimeConfig.init_config(JOB_SERVER_HOST=settings.HOST_IP, HTTP_PORT=settings.HOST_PORT)
    except Exception as e:
        logging.error(f"Runtime configuration failed: {e}")
        sys.exit(1)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # thread = ThreadPoolExecutor(max_workers=1)
    # thread.submit(update_progress)
    # å¯åŠ¨åå°ä»»åŠ¡
    executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="ragforge-bg")

    try:
        # å¯åŠ¨è¿›åº¦æ›´æ–°ä»»åŠ¡ - æ”¹ä¸ºå¾ªç¯ä»»åŠ¡è€Œä¸æ˜¯é€’å½’è°ƒç”¨
        executor.submit(safe_update_progress)

        # å¯åŠ¨å®šæœŸç»´æŠ¤ä»»åŠ¡
        executor.submit(periodic_maintenance)

        logging.info("Background tasks started successfully")

    except Exception as e:
        logging.error(f"Failed to start background tasks: {e}")

    # start http server
    # å¯åŠ¨HTTPæœåŠ¡å™¨
    try:
        logging.info("RAGForge HTTP server starting...")
        run_simple(
            hostname=settings.HOST_IP,
            port=settings.HOST_PORT,
            application=app,
            threaded=True,
            use_reloader=RuntimeConfig.DEBUG,
            use_debugger=RuntimeConfig.DEBUG,
        )
    except Exception as e:
        logging.error(f"HTTP server failed: {e}")
        logging.error(f"Full traceback: {traceback.format_exc()}")

        traceback.print_exc()
        # æ¸…ç†èµ„æº
        stop_event.set()
        try:
            executor.shutdown(wait=False)
            close_connection()
        except:
            pass

        time.sleep(1)
        os.kill(os.getpid(), signal.SIGKILL)

# å¦‚æœæœ‰å…¶ä»–ç±»ä¼¼çš„å®šæ—¶ä»»åŠ¡å‡½æ•°ï¼Œä¹Ÿéœ€è¦æ·»åŠ ç±»ä¼¼çš„é”™è¯¯å¤„ç†
def safe_database_operation(operation_name, operation_func, *args, **kwargs):
    """å®‰å…¨æ‰§è¡Œæ•°æ®åº“æ“ä½œçš„é€šç”¨å‡½æ•°"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            return operation_func(*args, **kwargs)
        except Exception as e:
            error_str = str(e).lower()
            is_db_error = any(keyword in error_str for keyword in [
                'closed cursor', 'connection', 'database', 'timeout'
            ])

            if is_db_error and attempt < max_retries - 1:
                logging.warning(f"Database connection issue in {operation_name} on attempt {attempt + 1}: {e}")
                try:
                    close_connection()
                    gc.collect()
                except:
                    pass
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                continue
            else:
                logging.error(f"{operation_name} exception: {e}")
                logging.error(f"Full traceback: {traceback.format_exc()}")
                return None
    return None
